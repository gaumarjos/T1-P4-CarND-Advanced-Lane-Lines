{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera calibration, distortion and warping functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def camera_calibration(img_size, verbose = False):\n",
    "    \n",
    "    # Number of corners in the checkboard\n",
    "    nx = 9\n",
    "    ny = 6\n",
    "\n",
    "    # Prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "    objp = np.zeros((ny*nx,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:nx, 0:ny].T.reshape(-1,2)\n",
    "\n",
    "    # Arrays to store object points and image points from all the images.\n",
    "    objpoints = [] # 3d points in real world space\n",
    "    imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "    # Make a list of calibration images\n",
    "    images = glob.glob('camera_cal/calibration*.jpg')\n",
    "\n",
    "    # Step through the list and search for chessboard corners\n",
    "    for idx, fname in enumerate(images):\n",
    "        img = cv2.imread(fname)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Find the chessboard corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (nx, ny), None)\n",
    "        if verbose:\n",
    "            print('Calibration image ' + fname + ': ' + str(ret))\n",
    "\n",
    "        # If found, add object points, image points\n",
    "        if ret == True:\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "\n",
    "            # Draw and display the corners\n",
    "            cv2.drawChessboardCorners(img, (8,6), corners, ret)\n",
    "            #write_name = 'corners_found'+str(idx)+'.jpg'\n",
    "            #cv2.imwrite(write_name, img)\n",
    "            #cv2.imshow('img', img)\n",
    "\n",
    "            if verbose:\n",
    "                f, ax = plt.subplots()\n",
    "                ax.imshow(img)\n",
    "    \n",
    "    # Compute calibration coefficients\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size, None, None)\n",
    "    \n",
    "    # Save for future use\n",
    "    dist_pickle = {}\n",
    "    dist_pickle[\"mtx\"] = mtx\n",
    "    dist_pickle[\"dist\"] = dist\n",
    "    pickle.dump( dist_pickle, open( \"camera_cal/calibration.p\", \"wb\" ) )\n",
    "    \n",
    "    return mtx, dist\n",
    "\n",
    "\n",
    "def undistort_image(img, mtx, dist):\n",
    "    dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    return dst\n",
    "\n",
    "\n",
    "def warp_image(img):\n",
    "    \n",
    "    #           1280          720\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    h = img.shape[0]\n",
    "    w = img.shape[1]\n",
    "    \n",
    "    src = np.float32([[575+5, 460],\n",
    "                      [w-575, 460],\n",
    "                      [260, 685],\n",
    "                      [w-260+20, 685]])\n",
    "    \n",
    "    side = 300\n",
    "    dst = np.float32([[side, 0],\n",
    "                      [w-side, 0],\n",
    "                      [side, h],\n",
    "                      [w-side, h]])\n",
    "    \n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "    \n",
    "    warped = cv2.warpPerspective(img, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "    return warped, M, Minv\n",
    "\n",
    "\n",
    "def region_of_interest(img):\n",
    "    \n",
    "    # Parameters of the region of interest\n",
    "    height = img.shape[0]\n",
    "    width = img.shape[1]\n",
    "    roi_h_center = width / 2\n",
    "    roi_v_center = 420\n",
    "    roi_flat_size = width / 20\n",
    "    roi_v_side_left = 0\n",
    "    roi_v_side_right = roi_v_side_left\n",
    "    roi_bottom = height\n",
    "    \n",
    "    # Vertices of the polygon describing the region of interest\n",
    "    vertices = np.array([[(0,roi_bottom),\n",
    "                          (0, height - roi_v_side_left),\n",
    "                          (roi_h_center-roi_flat_size/2, roi_v_center),\n",
    "                          (roi_h_center+roi_flat_size/2, roi_v_center),\n",
    "                          (width, height - roi_v_side_right),\n",
    "                          (width,roi_bottom)]],\n",
    "                        dtype=np.int32)\n",
    "    \n",
    "    # Defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    # Filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    # Returning the image only where mask pixels are nonzero\n",
    "    return cv2.bitwise_and(img, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_magnitude_threshold(img, sobel_kernel=3, thresh=(0, 255)):\n",
    "    \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    abs_sobel = np.sqrt(sobelx**2 + sobely**2)\n",
    "    \n",
    "    scaled_sobel = np.uint8(255 * abs_sobel / np.max(abs_sobel))\n",
    "    \n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    binary_output[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "    \n",
    "    return binary_output\n",
    "\n",
    "\n",
    "def gradient_direction_threshold(img, sobel_kernel=3, thresh_deg=(0., 90.)):\n",
    "    \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    sobelx = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel))\n",
    "    sobely = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel))\n",
    "    dir_sobel = np.arctan2(sobely, sobelx)\n",
    "    \n",
    "    thresh = (thresh_deg[0] / 180. * np.pi, thresh_deg[1] / 180. * np.pi)\n",
    "    binary_output = np.zeros_like(dir_sobel)\n",
    "    binary_output[(dir_sobel >= thresh[0]) & (dir_sobel <= thresh[1])] = 1\n",
    "    \n",
    "    blur_kernel = sobel_kernel\n",
    "    blurred = cv2.GaussianBlur(binary_output, (blur_kernel, blur_kernel), 0)\n",
    "    \n",
    "    return blurred\n",
    "\n",
    "\n",
    "def gradient_x_threshold(img, sobel_kernel=3, thresh=(0, 255)):\n",
    "    \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel))\n",
    "    scaled_sobel = np.uint8(255 * abs_sobel / np.max(abs_sobel))\n",
    "    \n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    binary_output[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "    \n",
    "    return binary_output\n",
    "\n",
    "\n",
    "def color_select(img):\n",
    "    \n",
    "    rgb_r = img[:,:,0]\n",
    "    \n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    hls_h = hls[:,:,0]\n",
    "    hls_l = hls[:,:,1]\n",
    "    hls_s = hls[:,:,2]\n",
    "    \n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
    "    lab_b = lab[:,:,2]\n",
    "    \n",
    "    ret, rgb_r_binary = cv2.threshold(rgb_r, 210, 255, cv2.THRESH_BINARY)\n",
    "    ret, hls_s_binary = cv2.threshold(hls_s, 175, 255, cv2.THRESH_BINARY)\n",
    "    ret, hls_l_binary = cv2.threshold(hls_l, 200, 255, cv2.THRESH_BINARY)\n",
    "    hls_l_binary2 = cv2.adaptiveThreshold(hls_l,\n",
    "                                          255,\n",
    "                                          cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "                                          cv2.THRESH_BINARY,\n",
    "                                          31,\n",
    "                                          -40)\n",
    "    ret, lab_b_binary = cv2.threshold(lab_b, 160, 255, cv2.THRESH_BINARY)\n",
    "    lab_b_binary2 = cv2.adaptiveThreshold(lab_b,\n",
    "                                          255,\n",
    "                                          cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "                                          cv2.THRESH_BINARY,\n",
    "                                          21,  # it's working for the first 2 videos with 15, but 25 looks better\n",
    "                                          -6)\n",
    "\n",
    "    \n",
    "    # Combine\n",
    "    combined_binary = np.zeros_like(hls_l_binary)\n",
    "    \"\"\"\n",
    "    combined_binary[(hls_s_binary == 255) |\n",
    "                    (hls_l_binary == 255) |\n",
    "                    (lab_b_binary == 255)] = 1\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    combined_binary[(hls_l_binary == 255) |\n",
    "                    (lab_b_binary == 255)] = 1\n",
    "    \"\"\"\n",
    "    combined_binary[(hls_l_binary == 255) |\n",
    "                    (lab_b_binary2 == 255)] = 1\n",
    "    \n",
    "    # Debug\n",
    "    if 0:\n",
    "        if 0:\n",
    "            f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "            ax1.imshow(lab_b, cmap='gray')\n",
    "            ax1.set_title('lab_b')\n",
    "            ax2.imshow(lab_b_binary, cmap='gray')\n",
    "            \n",
    "        if 1:\n",
    "            f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "            ax1.imshow(lab_b, cmap='gray')\n",
    "            ax1.set_title('lab_b2')\n",
    "            ax2.imshow(lab_b_binary2, cmap='gray')\n",
    "            \n",
    "        if 0:\n",
    "            f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "            ax1.imshow(hls_l, cmap='gray')\n",
    "            ax1.set_title('hls_l')\n",
    "            ax2.imshow(hls_l_binary, cmap='gray')\n",
    "            \n",
    "        if 0:\n",
    "            f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "            ax1.imshow(hls_l, cmap='gray')\n",
    "            ax1.set_title('hls_l2')\n",
    "            ax2.imshow(hls_l_binary2, cmap='gray')\n",
    "            \n",
    "        if 0:\n",
    "            f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "            ax1.imshow(hls_s, cmap='gray')\n",
    "            ax1.set_title('hls_s')\n",
    "            ax2.imshow(hls_s_binary, cmap='gray')\n",
    "            \n",
    "        if 0:\n",
    "            f, ax = plt.subplots(1, 1, figsize=(20,10))\n",
    "            ax.imshow(combined_binary, cmap='gray')\n",
    "            ax.set_title('combined')\n",
    "            \n",
    "    return combined_binary\n",
    "\n",
    "\n",
    "def image_processing_pipeline(img, mtx, dist):\n",
    "    \n",
    "    # Make a local copy\n",
    "    img = np.copy(img)\n",
    "    \n",
    "    # Produce the undistorted version of the original image. This goes directly to the output.\n",
    "    undistorted = undistort_image(img, mtx, dist)\n",
    "    \n",
    "    # Process the image to highlight lines\n",
    "    gradient_binary = gradient_x_threshold(img, sobel_kernel=9, thresh=(20, 100))\n",
    "    color_binary = color_select(img)\n",
    "    \n",
    "    # Stack each channel to view their individual contributions in green and blue respectively\n",
    "    # This returns a stack of the two binary images, whose components you can see as different colors\n",
    "    stacked_binary = np.dstack((np.zeros_like(gradient_binary),\n",
    "                                gradient_binary,\n",
    "                                color_binary))\n",
    "\n",
    "    # Combine the two binary thresholds\n",
    "    combined_binary = np.zeros_like(color_binary)\n",
    "    \"\"\"\n",
    "    combined_binary[(gradient_binary == 1) |\n",
    "                    (color_binary == 1)] = 1\n",
    "    \"\"\"\n",
    "    combined_binary[(color_binary == 1)] = 1\n",
    "    \n",
    "    # Region of interest\n",
    "    # region = region_of_interest(combined_binary)\n",
    "    \n",
    "    # Warping\n",
    "    processed, M, Minv = warp_image(undistort_image(combined_binary, mtx, dist))\n",
    "    \n",
    "    # Debug\n",
    "    if 0:\n",
    "        print(stacked_binary.shape)\n",
    "        print(combined_binary.shape)\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "        ax1.set_title('Stacked')\n",
    "        ax1.imshow(stacked_binary)\n",
    "        ax2.set_title('Combined')\n",
    "        ax2.imshow(combined_binary, cmap='gray')\n",
    "    \n",
    "    return undistorted, processed, M, Minv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Line detection functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lines_fit_new_frame(img, search_area='half', margin=80, show=False):\n",
    "    \n",
    "    # Histogram of the bottom half of the image (where less noisy line data are)\n",
    "    histogram = np.sum(img[img.shape[0]//2:,:], axis=0)\n",
    "    \n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]/2)\n",
    "    quarterpoint = np.int(midpoint/2)\n",
    "    if search_area == 'half':\n",
    "        leftx_base = np.argmax(histogram[:midpoint])\n",
    "        rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "    elif search_area == 'quarter':\n",
    "        leftx_base = np.argmax(histogram[quarterpoint:midpoint]) + quarterpoint\n",
    "        rightx_base = np.argmax(histogram[midpoint:(midpoint+quarterpoint)]) + midpoint\n",
    "    \n",
    "    # Number of sliding windows (vertical)\n",
    "    nwindows = 10\n",
    "    \n",
    "    # Set height of windows\n",
    "    window_height = np.int(img.shape[0] / nwindows)\n",
    "    \n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = img.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    # Current positions to be updated for each window\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "        \n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "    \n",
    "    # Empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "    \n",
    "    # Rectangle for visualization\n",
    "    rectangles = []\n",
    "    \n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        \n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = img.shape[0] - (window+1)*window_height\n",
    "        win_y_high = img.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        \n",
    "        # Append the data for the current rectangle. The actual drawing can be done later on if needed.\n",
    "        rectangles.append((win_y_low, win_y_high,\n",
    "                           win_xleft_low, win_xleft_high,\n",
    "                           win_xright_low, win_xright_high))\n",
    "        \n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        \n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        \n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "    \n",
    "    # Concatenate the arrays of indices\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit, right_fit = (None, None)\n",
    "    if len(leftx) is not 0:\n",
    "        left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    if len(rightx) is not 0:\n",
    "        right_fit = np.polyfit(righty, rightx, 2)\n",
    "        \n",
    "    left_linetype, right_linetype = detect_linetype(leftx, rightx)\n",
    "    \n",
    "    # Show results\n",
    "    if show:\n",
    "        # Create an output image to draw on and  visualize the result\n",
    "        out_img = np.dstack((img, img, img))*255\n",
    "        \n",
    "        # New figure and axis\n",
    "        f, ax = plt.subplots()\n",
    "        \n",
    "        # Generate x and y values for plotting\n",
    "        ploty = np.linspace(0, img.shape[0]-1, img.shape[0] )\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "        \n",
    "        # Draw the windows on the visualization image\n",
    "        for rectangle in rectangles:\n",
    "            cv2.rectangle(out_img,\n",
    "                          (rectangle[2],rectangle[0]),\n",
    "                          (rectangle[3],rectangle[1]),\n",
    "                          (0,255,0),2) \n",
    "            cv2.rectangle(out_img,\n",
    "                          (rectangle[4],rectangle[0]),\n",
    "                          (rectangle[5],rectangle[1]),\n",
    "                          (0,255,0), 2)\n",
    "        \n",
    "\n",
    "        # Left line pixels in red and right line pixels in blue\n",
    "        out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "        out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "        \n",
    "        # Plot image\n",
    "        plt.imshow(out_img)\n",
    "        \n",
    "        # Fitted lines\n",
    "        plt.plot(left_fitx, ploty, color='yellow')\n",
    "        plt.plot(right_fitx, ploty, color='yellow')\n",
    "        \n",
    "        plt.xlim(0, 1280)\n",
    "        plt.ylim(720, 0)\n",
    "        \n",
    "    return left_fit, right_fit, left_lane_inds, right_lane_inds, left_linetype, right_linetype\n",
    "\n",
    "\n",
    "def lines_fit_based_on_previous_frame(img, prev_left_fit, prev_right_fit, margin=80, show=False):\n",
    "\n",
    "    # Assume you now have a new warped binary image\n",
    "    nonzero = img.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    left_lane_inds = ((nonzerox > (prev_left_fit[0]*(nonzeroy**2) + prev_left_fit[1]*nonzeroy + prev_left_fit[2] - margin)) & \n",
    "                      (nonzerox < (prev_left_fit[0]*(nonzeroy**2) + prev_left_fit[1]*nonzeroy + prev_left_fit[2] + margin))) \n",
    "    right_lane_inds = ((nonzerox > (prev_right_fit[0]*(nonzeroy**2) + prev_right_fit[1]*nonzeroy + prev_right_fit[2] - margin)) & \n",
    "                       (nonzerox < (prev_right_fit[0]*(nonzeroy**2) + prev_right_fit[1]*nonzeroy + prev_right_fit[2] + margin)))  \n",
    "\n",
    "    # Again, extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "    \n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit, right_fit = (None, None)\n",
    "    if len(leftx) != 0:\n",
    "        # Fit a second order polynomial to each\n",
    "        left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    if len(rightx) != 0:\n",
    "        right_fit = np.polyfit(righty, rightx, 2)\n",
    "        \n",
    "    left_linetype, right_linetype = detect_linetype(leftx, rightx)\n",
    "        \n",
    "    # Show results\n",
    "    if show:\n",
    "        # Create an image to draw on and an image to show the selection window\n",
    "        out_img = np.dstack((img, img, img))*255\n",
    "        window_img = np.zeros_like(out_img)\n",
    "        \n",
    "        # Generate x and y values for plotting\n",
    "        ploty = np.linspace(0, img.shape[0]-1, img.shape[0])\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "        \n",
    "        # Left line pixels in red and right line pixels in blue\n",
    "        out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "        out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "\n",
    "        # Generate a polygon to illustrate the search window area (based on the old fit)\n",
    "        # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "        left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "        left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, ploty])))])\n",
    "        left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "        right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "        right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, ploty])))])\n",
    "        right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "\n",
    "        # Draw the lane onto the warped blank image\n",
    "        cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "        cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,255, 0))\n",
    "        result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "        plt.imshow(result)\n",
    "        plt.plot(left_fitx, ploty, color='yellow')\n",
    "        plt.plot(right_fitx, ploty, color='yellow')\n",
    "        plt.xlim(0, 1280)\n",
    "        plt.ylim(720, 0)\n",
    "        \n",
    "    return left_fit, right_fit, left_lane_inds, right_lane_inds, left_linetype, right_linetype\n",
    "\n",
    "\n",
    "def detect_linetype(leftx, rightx, balance_thresh=1.4, continuous_thresh=8000):\n",
    "    # Detect which line is continuous and which not\n",
    "    left_npoints = np.float(leftx.shape[0])\n",
    "    right_npoints = np.float(rightx.shape[0])\n",
    "    if right_npoints == 0:\n",
    "        balance = 100\n",
    "    else:\n",
    "        balance = left_npoints / right_npoints\n",
    "    \n",
    "    # 0 = dashed\n",
    "    # 1 = continuous\n",
    "    if balance > balance_thresh:\n",
    "        return 1., 0.\n",
    "    elif balance < 1/balance_thresh:\n",
    "        return 0., 1.\n",
    "    else:\n",
    "        if (left_npoints + right_npoints) / 2 > continuous_thresh:\n",
    "            return 1., 1.\n",
    "        else:\n",
    "            return 0., 0.\n",
    "        \n",
    "\n",
    "def curvature_radius_and_distance_from_centre(img, left_fit, right_fit,\n",
    "                                                   left_lane_inds, right_lane_inds):\n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension, lane line is 10 ft = 3.048 meters\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension, lane width is 12 ft = 3.7 meters\n",
    "    \n",
    "    # Default values\n",
    "    left_curverad, right_curverad, center_dist = (0, 0, 0)\n",
    "    \n",
    "    # It's important where you want to measure the radius.\n",
    "    # In this case, I chose the bottom of the image\n",
    "    curvature_h = img.shape[0]\n",
    "    ploty = np.linspace(0, curvature_h-1, curvature_h)\n",
    "    y_eval = np.max(ploty)\n",
    "  \n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = img.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    # Again, extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "    \n",
    "    # Default output values\n",
    "    left_curve_radius = None\n",
    "    right_curve_radius = None\n",
    "    centre_dist = None\n",
    "    \n",
    "    if len(leftx) != 0 and len(rightx) != 0:\n",
    "        # Fit new polynomials to x,y in world space\n",
    "        left_fit_cr = np.polyfit(lefty*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "        right_fit_cr = np.polyfit(righty*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "        \n",
    "        # Calculate the new radii of curvature in meters\n",
    "        left_curve_radius = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "        right_curve_radius = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "        \n",
    "    # Distance from center is image x midpoint - mean of l_fit and r_fit intercepts \n",
    "    if left_fit is not None and right_fit is not None:\n",
    "        car_position = img.shape[1]/2  # based on camera\n",
    "        left_fit_x_int = left_fit[0]*curvature_h**2 + left_fit[1]*curvature_h + left_fit[2]\n",
    "        right_fit_x_int = right_fit[0]*curvature_h**2 + right_fit[1]*curvature_h + right_fit[2]\n",
    "        lane_centre_position = (right_fit_x_int + left_fit_x_int) /2\n",
    "        centre_dist = (car_position - lane_centre_position) * xm_per_pix\n",
    "        \n",
    "    return left_curve_radius, right_curve_radius, centre_dist\n",
    "\n",
    "\n",
    "def draw_on_image(original_img, binary_img,\n",
    "                  left_fit, right_fit,\n",
    "                  left_lane_inds, right_lane_inds,\n",
    "                  Minv,\n",
    "                  left_curve_radius=None,\n",
    "                  right_curve_radius=None,\n",
    "                  centre_dist=None,\n",
    "                  left_linetype=None,\n",
    "                  right_linetype=None,\n",
    "                  show_processed=True,\n",
    "                  show=False):\n",
    "    \n",
    "    # Make a copy of the original image\n",
    "    original_img_copy = np.copy(original_img)\n",
    "    if left_fit is None or right_fit is None:\n",
    "        return original_img_copy\n",
    "    \n",
    "    # Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(binary_img).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "    \n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, img.shape[0]-1, img.shape[0])\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    \n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "    \n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "    cv2.polylines(color_warp, np.int32([pts_left]), isClosed=False, color=(255,0,255), thickness=25)\n",
    "    cv2.polylines(color_warp, np.int32([pts_right]), isClosed=False, color=(0,255,255), thickness=25)\n",
    "    \n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (original_img_copy.shape[1], original_img_copy.shape[0])) \n",
    "    \n",
    "    # Combine the result with the original image\n",
    "    original_image_with_lines = cv2.addWeighted(original_img_copy, 1, newwarp, 0.3, 0)\n",
    "    \n",
    "    # Add curvature radius. The continuous line has more weight than the dashed one.\n",
    "    font = cv2.FONT_HERSHEY_DUPLEX\n",
    "    if left_curve_radius is not None and right_curve_radius is not None:\n",
    "        if left_linetype > 0.5 and right_linetype < 0.5:\n",
    "            weights = [10.0, 1.0]\n",
    "        elif left_linetype < 0.5 and right_linetype > 0.5:\n",
    "            weights = [1.0, 10.0]\n",
    "        else:\n",
    "            weights = [1.0, 1.0]\n",
    "        curve_radius = np.average([left_curve_radius, right_curve_radius], weights=weights)\n",
    "        \n",
    "        text = 'Radius: ' + '{:04.2f}'.format(curve_radius) + 'm'\n",
    "        cv2.putText(original_image_with_lines, text, (40,70), font, 1.5, (255,255,255), 2, cv2.LINE_AA)\n",
    "    \n",
    "    # Add distance from centre, if provided\n",
    "    if centre_dist is not None:\n",
    "        if centre_dist > 0:\n",
    "            direction = 'right'\n",
    "        else:\n",
    "            direction = 'left'\n",
    "        text = '{:04.2f}'.format(abs(centre_dist)) + 'm ' + direction + ' of centre'\n",
    "        cv2.putText(original_image_with_lines, text, (40,120), font, 1.5, (255,255,255), 2, cv2.LINE_AA)\n",
    "    \n",
    "    if 0:\n",
    "        if left_linetype is not None and right_linetype is not None:\n",
    "            text = 'L: {}  R: {}'.format(left_linetype, right_linetype)\n",
    "            cv2.putText(original_image_with_lines, text, (40,170), font, 1.5, (255,255,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "    # Show processed image in a box on the upper right corner\n",
    "    if show_processed:\n",
    "        \n",
    "        # Create an image to draw on and an image to show the selection window\n",
    "        out_img = np.dstack((binary_img, binary_img, binary_img))*255\n",
    "        window_img = np.zeros_like(out_img)\n",
    "        \n",
    "        # Left line pixels in red and right line pixels in blue\n",
    "        nonzero = binary_img.nonzero()\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "        out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "        \n",
    "        # Draw fit line\n",
    "        margin = 5\n",
    "        left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "        left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, ploty])))])\n",
    "        left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "        right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "        right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, ploty])))])\n",
    "        right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "        \n",
    "        # Draw the lane onto the warped blank image\n",
    "        cv2.fillPoly(window_img, np.int_([left_line_pts]), (255, 255, 0))\n",
    "        cv2.fillPoly(window_img, np.int_([right_line_pts]), (255, 255, 0))\n",
    "        little_img = cv2.addWeighted(out_img, 1, window_img, 1., 0)\n",
    "        \n",
    "        little_img = cv2.resize(little_img, None,\n",
    "                                      fx=0.25, fy=0.25,\n",
    "                                      interpolation = cv2.INTER_CUBIC)\n",
    "        original_image_with_lines[40:40+little_img.shape[0], \\\n",
    "                                  original_image_with_lines.shape[1] - little_img.shape[1] - 40 : \\\n",
    "                                  original_image_with_lines.shape[1] - 40] = little_img\n",
    "    \n",
    "    if show:\n",
    "        f, ax = plt.subplots()\n",
    "        ax.imshow(original_image_with_lines)\n",
    "        \n",
    "    return original_image_with_lines\n",
    "\n",
    "\n",
    "# Define a class to receive the characteristics of each line detection\n",
    "class Line():\n",
    "    def __init__(self):\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False  \n",
    "        # x values of the last n fits of the line\n",
    "        self.recent_xfitted = [] \n",
    "        #average x values of the fitted line over the last n iterations\n",
    "        self.bestx = None     \n",
    "        #polynomial coefficients averaged over the last n iterations\n",
    "        self.best_fit = None  \n",
    "        #polynomial coefficients for the most recent fit\n",
    "        self.fits_history = []#[np.array([False])]  \n",
    "        #radius of curvature of the line in some units\n",
    "        self.radius_of_curvature = None \n",
    "        #distance in meters of vehicle center from the line\n",
    "        self.line_base_pos = None \n",
    "        #difference in fit coefficients between last and new fits\n",
    "        self.diffs = np.array([0,0,0], dtype='float') \n",
    "        #x values for detected line pixels\n",
    "        self.allx = None  \n",
    "        #y values for detected line pixels\n",
    "        self.ally = None\n",
    "        #number of detected pixels\n",
    "        # self.px_count = None\n",
    "        \n",
    "        # line type (0=dashed, 1=continuous)\n",
    "        self.best_linetype = 0.\n",
    "        self.linetypes_history = []\n",
    "           \n",
    "        # Maximum memory depth\n",
    "        self.N = 10\n",
    "    \n",
    "    def add_fit(self, fit, inds, linetype):\n",
    "        \n",
    "        # The last iteration produced a fit\n",
    "        if fit is not None:\n",
    "            \n",
    "            # We already have a best fit in memory\n",
    "            if self.best_fit is not None:\n",
    "                self.diffs = abs(fit-self.best_fit)\n",
    "                \n",
    "            # The new fit is way too different from the best fit we have in memory,\n",
    "            # we'll do as if we had no fit. However, an exception \n",
    "            if (self.diffs[0] > 0.01 or self.diffs[1] > 1.0 or self.diffs[2] > 1000.0) and \\\n",
    "               len(self.fits_history) > 0:\n",
    "                # We haven't detected a fit\n",
    "                self.detected = False\n",
    "                \n",
    "                # We have a list of old fits\n",
    "                if len(self.fits_history) > 0:\n",
    "                    # We do with what we have\n",
    "                    self.best_fit = np.average(self.fits_history, axis=0)\n",
    "            \n",
    "            # The new fit is not too different from the best fit we have in memory\n",
    "            else:\n",
    "                # We detected a fit\n",
    "                self.detected = True\n",
    "                # Append the fit to the list of fits\n",
    "                self.fits_history.append(fit)\n",
    "                if len(self.fits_history) > self.N:\n",
    "                    # Remove last element\n",
    "                    self.fits_history = self.fits_history[len(self.fits_history)-self.N:]\n",
    "                # Compute the best fit using the new one\n",
    "                self.best_fit = np.average(self.fits_history, axis=0)\n",
    "            \n",
    "            ## Line type\n",
    "            # Append the line type to the list of line types\n",
    "            self.linetypes_history.append(linetype)\n",
    "            if len(self.linetypes_history) > self.N:\n",
    "                # Remove last element\n",
    "                self.linetypes_history = self.linetypes_history[len(self.linetypes_history)-self.N:]\n",
    "            # Compute the best fit using the new one\n",
    "            self.best_linetype = np.round(np.average(self.linetypes_history, axis=0))\n",
    "        \n",
    "        # The last iteration didn't produce a fit, we need to live with what we have\n",
    "        else:\n",
    "            # We haven't detected a fit\n",
    "            self.detected = False\n",
    "            \n",
    "            # We don't want the list to become too old, otherwise the line can get stuck in some position\n",
    "            # and never recover from there (e.g. challenge video)\n",
    "            if len(self.fits_history) > 0:\n",
    "                self.fits_history = self.fits_history[:len(self.fits_history)-1]\n",
    "            \n",
    "            # We have a list of old fits\n",
    "            if len(self.fits_history) > 0:\n",
    "                # We do with what we have\n",
    "                self.best_fit = np.average(self.fits_history, axis=0)\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pipeline(img):\n",
    "    \n",
    "    image = img.copy()\n",
    "    \n",
    "    # Image processing\n",
    "    undistorted, processed, M, Minv = image_processing_pipeline(image, mtx, dist)\n",
    "    \n",
    "    # Decide whether to work on a new frame or use info from the previous frame\n",
    "    if not left_line.detected or not right_line.detected:\n",
    "        left_fit, \\\n",
    "        right_fit, \\\n",
    "        left_lane_inds, \\\n",
    "        right_lane_inds, \\\n",
    "        left_linetype, \\\n",
    "        right_linetype = lines_fit_new_frame(processed,\n",
    "                                             show=False)\n",
    "    else:\n",
    "        left_fit, \\\n",
    "        right_fit, \\\n",
    "        left_lane_inds, \\\n",
    "        right_lane_inds, \\\n",
    "        left_linetype, \\\n",
    "        right_linetype = lines_fit_based_on_previous_frame(processed,\n",
    "                                                           prev_left_fit=left_line.best_fit,\n",
    "                                                           prev_right_fit=right_line.best_fit,\n",
    "                                                           show=False)\n",
    "    \n",
    "    # Now we have a fit, check conditions to decide whether this fit makes sense or not.\n",
    "    # If it does, add it to the list of good fits in the left_line and right_line objects, else, just\n",
    "    # say no good fit comes from this frame and let the object decide which of the previous ones makes\n",
    "    # sense to use\n",
    "    \n",
    "    # TODO: for the moment, every new fit is a good fit, worth object's attention\n",
    "    left_line.add_fit(left_fit, left_lane_inds, left_linetype)\n",
    "    right_line.add_fit(right_fit, right_lane_inds, right_linetype)\n",
    "    \n",
    "    # Use the best fit, if it's the current one or some previous, is the object's decision\n",
    "    if left_line.best_fit is not None and right_line.best_fit is not None:\n",
    "        \n",
    "        # Compute curvature and distance from centre\n",
    "        left_curve_radius, \\\n",
    "        right_curve_radius, \\\n",
    "        centre_dist = curvature_radius_and_distance_from_centre(processed,\n",
    "                                                                left_line.best_fit,\n",
    "                                                                right_line.best_fit,\n",
    "                                                                left_lane_inds,        # possible error?\n",
    "                                                                right_lane_inds)       # possible error?\n",
    "        \n",
    "        # Produce output\n",
    "        undistorted_with_lines = draw_on_image(undistorted, processed,\n",
    "                                               left_line.best_fit,\n",
    "                                               right_line.best_fit,\n",
    "                                               left_lane_inds,\n",
    "                                               right_lane_inds,\n",
    "                                               Minv,\n",
    "                                               left_curve_radius=left_curve_radius,\n",
    "                                               right_curve_radius=right_curve_radius,\n",
    "                                               centre_dist=centre_dist,\n",
    "                                               left_linetype=left_line.best_linetype,\n",
    "                                               right_linetype=right_line.best_linetype,\n",
    "                                               show_processed=True,\n",
    "                                               show=False)\n",
    "        \n",
    "        return undistorted_with_lines\n",
    "    \n",
    "    else:\n",
    "        return undistorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use example\n",
    "\n",
    "https://classroom.udacity.com/nanodegrees/nd013/parts/fbf77062-5703-404e-b60c-95b78b2f3f9e/modules/2b62a1c3-e151-4a0e-b6b6-e424fa46ceab/lessons/40ec78ee-fb7c-4b53-94a8-028c5c60b858/concepts/2f928913-21f6-4611-9055-01744acc344f\n",
    "\n",
    "https://github.com/jeremy-shannon/CarND-Advanced-Lane-Lines/blob/master/project.ipynb\n",
    "\n",
    "https://github.com/ksakmann/CarND-Advanced-Lane-Lines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distortion and warping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = 'test_images/test1.jpg'\n",
    "img = cv2.imread(filename)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img_size = (img.shape[1], img.shape[0])\n",
    "\n",
    "mtx, dist = camera_calibration(img_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary: Extract frames from video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from moviepy.editor import *\n",
    "\n",
    "def extract_frames(movie, times, imgdir, image):\n",
    "    clip = VideoFileClip(movie)\n",
    "    for i, t in enumerate(times):\n",
    "        # imgpath = os.path.join(imgdir, '{}.png'.format(t))\n",
    "        imgpath = os.path.join(imgdir, 'harder_challenge{}.jpg'.format(i))\n",
    "        clip.save_frame(imgpath, t)\n",
    "\n",
    "#videofile = \"test_videos/project_video.mp4\"\n",
    "#videofile = \"test_videos/challenge_video.mp4\"\n",
    "videofile = \"test_videos/harder_challenge_video.mp4\"\n",
    "imagefile = 'test7'\n",
    "#times = [1., 3., 6., 10., 13., 15.]\n",
    "times = [5., 9., 12., 14.8, 17., 23., 26., 29., 34., 36., 39., 42.]\n",
    "\n",
    "extract_frames(videofile, times, 'test_images', imagefile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images = glob.glob('test_images/*.jpg')\n",
    "for idx, fname in enumerate(images):\n",
    "    img = cv2.imread(fname)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    mag_binary = gradient_magnitude_threshold(img, sobel_kernel=9, thresh=(30, 100))\n",
    "    dir_binary = gradient_direction_threshold(img, sobel_kernel=15, thresh_deg=(35., 75.))\n",
    "    x_binary   = gradient_x_threshold(img, sobel_kernel=9, thresh=(20, 100))\n",
    "\n",
    "    combined = np.zeros_like(dir_binary)\n",
    "    combined[((mag_binary == 1) & (dir_binary == 1))] = 1\n",
    "    \n",
    "    f, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(24, 9))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title('Original Image', fontsize=20)\n",
    "    ax2.imshow(mag_binary, cmap='gray')\n",
    "    ax2.set_title('Thresholded Gradient Magnitude', fontsize=20)\n",
    "    ax3.imshow(dir_binary, cmap='gray')\n",
    "    ax3.set_title('Thresholded Gradient Direction', fontsize=20)\n",
    "    ax4.imshow(x_binary, cmap='gray')\n",
    "    ax4.set_title('X', fontsize=20)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# images = glob.glob('test_images/test*.jpg')\n",
    "# images = glob.glob('test_images/challenge*.jpg')\n",
    "images = glob.glob('test_images/harder_challenge*.jpg')\n",
    "for idx, fname in enumerate(images):\n",
    "    img = cv2.imread(fname)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    color_select(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline test on single images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all test images\n",
    "# images = glob.glob('test_images/*.jpg')\n",
    "images = ['test_images/straight_lines1.jpg']\n",
    "#mages = ['test_images/test8.jpg']\n",
    "for idx, fname in enumerate(images):\n",
    "    img = cv2.imread(fname)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Test only the image processing pipeline\n",
    "    if 1:\n",
    "        undistorted, processed, M, Minv = image_processing_pipeline(img, mtx, dist)\n",
    "        \n",
    "        f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "        ax1.imshow(img)\n",
    "        ax1.set_title('Original', fontsize=20)\n",
    "\n",
    "        ax2.imshow(processed, cmap='gray')\n",
    "        ax2.set_title('Processed', fontsize=20)\n",
    "        ax2.grid(True)\n",
    "        \n",
    "    # Test the whole pipeline\n",
    "    if 0:\n",
    "        left_line = Line()\n",
    "        right_line = Line()\n",
    "        output = pipeline(img)\n",
    "        f, ax = plt.subplots()\n",
    "        ax.imshow(output)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline test on video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "filename = \"test_videos/project_video.mp4\"\n",
    "# filename = \"test_videos/challenge_video.mp4\"\n",
    "# filename = \"test_videos/harder_challenge_video.mp4\"\n",
    "clip = VideoFileClip(filename)\n",
    "white_output = filename[:-4] + '_output.mp4'\n",
    "\n",
    "# Video boundaries\n",
    "start_second = 18\n",
    "end_second = 27\n",
    "\n",
    "# Variables used by function \"pipeline\"\n",
    "left_line = Line()\n",
    "right_line = Line()\n",
    "white_clip = clip.fl_image(pipeline)#.subclip(start_second,end_second)\n",
    "\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
